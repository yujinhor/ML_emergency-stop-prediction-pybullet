import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import MinMaxScaler

# ====================================================
# 1. íŒŒì¼ ê²½ë¡œ ë° ì„¤ì • (Configuration)
# ====================================================
base_path = os.path.dirname(os.path.abspath(__file__))

# í•™ìŠµìš© íŒŒì¼
train_steps_path = os.path.join(base_path, 'train_steps.csv')
train_summary_path = os.path.join(base_path, 'train_summary.csv')

# íƒœìŠ¤íŠ¸ íŒŒì¼
test_steps_path = os.path.join(base_path, 'val_steps.csv')
test_summary_path = os.path.join(base_path, 'val_summary.csv')

# ì„¤ì •ê°’
target_col = 'result_is_failure'  # ì •ë‹µ ì»¬ëŸ¼ ì´ë¦„
SEQ_LEN = 2400                    # ì‹œí€€ìŠ¤ ê¸¸ì´, ì‹¤íŒ¨ ë°ì´í„°ì—ì„œ ì œì¼ ê¸´ ë°ì´í„°ê°€ 2359ì˜€ìœ¼ë¯€ë¡œ ë‹¤ ê°€ì ¸ê°€ê¸°ë¡œ..
feature_cols = [                  # ì…ë ¥ìœ¼ë¡œ ì“¸ ë³€ìˆ˜ë“¤
    'speed', 'dist_to_wall', 'drag_force_N', 
    'mass_kg', 'friction_cond', 'air_density', 'trigger_dist_m', 'brake_torque', 'init_speed_cmd'
]
static_cols_to_merge = [          # surmmary íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¬ ë¬¼ë¦¬ ë³€ìˆ˜ë“¤
    'episode', 'mass_kg', 'friction_cond', 'air_density', 'brake_torque', 'init_speed_cmd'
]

# ====================================================
# 2. ë°ì´í„° ë¡œë“œ ë° ë³‘í•© í•¨ìˆ˜ (Load & Merge Function)
# ====================================================
def load_and_merge(steps_path, summary_path, mode="Train"):
    print(f"\n[{mode}] ë°ì´í„° ë¡œë“œ ì¤‘...")
    if not os.path.exists(steps_path) or not os.path.exists(summary_path):
        print(f"âš ï¸ {mode} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None

    df_steps = pd.read_csv(steps_path)
    df_summary = pd.read_csv(summary_path)
    


    # ë³‘í•©
    df_merged = pd.merge(df_steps, df_summary[static_cols_to_merge], on='episode', how='left')
    
    # ì¤‘ë³µ ì œê±°
    if f'{target_col}_y' in df_merged.columns:
        df_merged = df_merged.rename(columns={f'{target_col}_y': target_col})
        if f'{target_col}_x' in df_merged.columns:
            df_merged = df_merged.drop(columns=[f'{target_col}_x'])

    print(f"[{mode}] ë³‘í•© ì™„ë£Œ: {df_merged.shape}")
    return df_merged

# Train, Test ê°ê° ë¡œë“œ
train_df = load_and_merge(train_steps_path, train_summary_path, "Train")
test_df = load_and_merge(test_steps_path, test_summary_path, "Test")

# ====================================================
# 3. ìŠ¤ì¼€ì¼ë§ (Scaling) 
# ====================================================
scaler = MinMaxScaler()

# 1. Train ë°ì´í„°ë¡œ ê¸°ì¤€ ë§Œë“ ë‹¤. 
scaler.fit(train_df[feature_cols])
print("\n Scaler í•™ìŠµ ì™„ë£Œ (Train ë°ì´í„° ê¸°ì¤€)")

# 2. ê·¸ ìë¡œ Train ë°ì´í„°ë¥¼ ì½ë‹ˆë‹¤. (Transform)
train_df[feature_cols] = scaler.transform(train_df[feature_cols])

# 3. ê°™ì€ ê¸°ì¤€ìœ¼ë¡œ Test ë°ì´í„° ìŠ¤ì¼€ì¼ë§. (Transform only)
if test_df is not None:
    test_df[feature_cols] = scaler.transform(test_df[feature_cols])
    print("Test ë°ì´í„° ë³€í™˜ ì™„ë£Œ (Train ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ë¨)")

# ====================================================
# 4. 3ì°¨ì› í…ì„œ ë³€í™˜ (Windowing)
# ====================================================
def create_sequences(df, seq_len):
    if df is None: return None, None
    
    episode_ids = df['episode'].unique()
    X_list = []
    y_list = []
    
    for ep in episode_ids:
        group = df[df['episode'] == ep]
        features = group[feature_cols].values
        
        # ì •ë‹µ ë¼ë²¨ (ì—í”¼ì†Œë“œ ë§ˆì§€ë§‰ ê°’)
        label = group[target_col].iloc[-1]
        
        # Windowing (Tail Truncation & Padding)
        if len(features) >= seq_len:
            features = features[-seq_len:, :]
        else:
            pad_len = seq_len - len(features)
            features = np.pad(features, ((0 ,pad_len), (0, 0)), mode='constant')
            
        X_list.append(features)
        y_list.append(label)
        
    return np.array(X_list), np.array(y_list)

# ë³€í™˜ ì‹¤í–‰
print("\n[Tensor ë³€í™˜ ì¤‘...]")
X_train, y_train = create_sequences(train_df, SEQ_LEN)
X_test, y_test = create_sequences(test_df, SEQ_LEN)

# ====================================================
# 5. ë°ì´í„° ì €ì¥ (Save)
# ====================================================
save_dir = os.path.join(base_path, 'processed_datas')
if not os.path.exists(save_dir):
    os.makedirs(save_dir)

print(f"\n[ì €ì¥ ì‹œì‘] ê²½ë¡œ: {save_dir}")

'''# ì—‘ì…€(CSV) í™•ì¸ìš© íŒŒì¼ ì €ì¥
# ìŠ¤ì¼€ì¼ë§ ëœ ê°’ë“¤ê³¼ ë¼ë²¨(result_is_failure)ì´ ëª¨ë‘ ë“¤ì–´ìˆëŠ” í‘œ ë°ì´í„°.
train_csv_path = os.path.join(save_dir, 'train_data_scaled.csv')
train_df.to_csv(train_csv_path, index=False)
print(f"[ì—‘ì…€ìš©] Train ë°ì´í„°(ë¼ë²¨ í¬í•¨) ì €ì¥ ì™„ë£Œ: {train_csv_path}")

if test_df is not None:
    test_csv_path = os.path.join(save_dir, 'test_data_scaled.csv')
    test_df.to_csv(test_csv_path, index=False)
    print(f"[ì—‘ì…€ìš©] Test ë°ì´í„°(ë¼ë²¨ í¬í•¨) ì €ì¥ ì™„ë£Œ: {test_csv_path}")'''



# Train ì €ì¥
np.save(os.path.join(save_dir, 'X_train.npy'), X_train)
np.save(os.path.join(save_dir, 'y_train.npy'), y_train)
print(f"ğŸ“Œ Train í…ì„œ ì €ì¥ ì™„ë£Œ: {X_train.shape}")

# Test ì €ì¥ (íŒŒì¼ì´ ìˆì—ˆì„ ê²½ìš°ë§Œ)
if X_test is not None:
    np.save(os.path.join(save_dir, 'X_test.npy'), X_test)
    np.save(os.path.join(save_dir, 'y_test.npy'), y_test)
    print(f"ğŸ“Œ Test í…ì„œ ì €ì¥ ì™„ë£Œ: {X_test.shape}")

print("-" * 50)
print("ë!")