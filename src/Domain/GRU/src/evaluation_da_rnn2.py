import torch
import torch.nn as nn
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import torch.nn.functional as F
import sys
import os

# ----------------------------------------------------
# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ (Max Poolingëœ ë°ì´í„°)
# ----------------------------------------------------
# Mac(M1/M2) 'mps' ë˜ëŠ” 'cpu'
device = torch.device("mps") if torch.backends.mps.is_available() else torch.device("cpu")
print(f"ğŸš€ í‰ê°€ ì¥ì¹˜: {device}")

INPUT_SIZE = 8       # Feature ê°œìˆ˜
HIDDEN_SIZE = 64     # Hidden Size

def load_test_data():
    print("ğŸ“‚ Max Pooling í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘...")
    try:
        X_test = np.load('X_test_maxpool.npy')
        
        # y_testëŠ” ì ‘ë‘ì‚¬ê°€ ë¶™ì€ ê²Œ ìˆìœ¼ë©´ ê·¸ê±° ì“°ê³ , ì—†ìœ¼ë©´ ì›ë³¸ ì‚¬ìš©
        if os.path.exists('y_test_maxpool.npy'):
            y_test = np.load('y_test_maxpool.npy')
        else:
            y_test = np.load('y_test.npy')
            
        # Tensor ë³€í™˜
        X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)
        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)
        
        print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: X shape {X_test.shape}")
        return X_test_tensor, y_test_tensor
        
    except FileNotFoundError:
        print("âŒ ì˜¤ë¥˜: 'X_test_maxpool.npy' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ë¥¼ ë¨¼ì € ì§„í–‰í•˜ì„¸ìš”.")
        sys.exit()

X_test, y_test = load_test_data()
test_dataset = TensorDataset(X_test, y_test)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# ----------------------------------------------------
# 2. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼)
# ----------------------------------------------------
class InputAttention(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(InputAttention, self).__init__()
        self.linear = nn.Linear(hidden_size + input_size, input_size)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x_t, h_prev):
        combined = torch.cat((x_t, h_prev), dim=1)
        scores = torch.tanh(self.linear(combined))
        alpha = self.softmax(scores) 
        return alpha * x_t, alpha

class TemporalAttention(nn.Module):
    def __init__(self, hidden_size):
        super(TemporalAttention, self).__init__()
        self.linear = nn.Linear(hidden_size, 1)

    def forward(self, encoder_outputs):
        scores = torch.tanh(self.linear(encoder_outputs))
        beta = F.softmax(scores, dim=1) 
        context = torch.sum(beta * encoder_outputs, dim=1)
        return context, beta

class DA_RNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(DA_RNN, self).__init__()
        self.hidden_size = hidden_size
        self.input_attention = InputAttention(input_size, hidden_size)
        self.gru_cell = nn.GRUCell(input_size, hidden_size)
        self.temporal_attention = TemporalAttention(hidden_size)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        batch_size, seq_len, _ = x.size()
        h_t = torch.zeros(batch_size, self.hidden_size).to(x.device)
        encoder_outputs = []
        
        for t in range(seq_len):
            x_t = x[:, t, :]
            weighted_x_t, _ = self.input_attention(x_t, h_t)
            h_t = self.gru_cell(weighted_x_t, h_t)
            encoder_outputs.append(h_t.unsqueeze(1))
            
        encoder_outputs = torch.cat(encoder_outputs, dim=1)
        context_vector, _ = self.temporal_attention(encoder_outputs)
        logits = self.fc(context_vector)
        return torch.sigmoid(logits)

# ----------------------------------------------------
# 3. ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡
# ----------------------------------------------------
model = DA_RNN(input_size=INPUT_SIZE, hidden_size=HIDDEN_SIZE, output_size=1).to(device)

MODEL_PATH = 'da_rnn_best_maxpool.pth'
try:
    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
    model.eval()
    print(f"âœ… í•™ìŠµëœ ëª¨ë¸ '{MODEL_PATH}' ë¡œë“œ ì„±ê³µ!")
except FileNotFoundError:
    print(f"âŒ ì˜¤ë¥˜: '{MODEL_PATH}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµì´ ì™„ë£Œë˜ì—ˆë‚˜ìš”?")
    sys.exit()

def get_predictions(model, loader):
    all_probs = []
    with torch.no_grad():
        for inputs, _ in loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            outputs = outputs.squeeze()
            all_probs.extend(outputs.cpu().numpy().flatten())
    return np.array(all_probs)

print("ğŸ¤– ì˜ˆì¸¡ ìˆ˜í–‰ ì¤‘...")
targets_np = y_test.numpy().flatten()
probs_np = get_predictions(model, test_loader)

# ----------------------------------------------------
# 4. ìµœì  ì„ê³„ì¹˜ íƒìƒ‰ ë° ê²°ê³¼ ì¶œë ¥
# ----------------------------------------------------
best_f1 = 0
best_th = 0.5

print("\n" + "="*45)
print("ğŸ” Threshold Optimization (DA-RNN MaxPool)")
print("="*45)
print(f"{'Threshold':<10} | {'F1 Score':<10} | {'Accuracy':<10}")
print("-" * 45)

for th in np.arange(0.1, 0.91, 0.05):
    preds = (probs_np > th).astype(int)
    f1 = f1_score(targets_np, preds, zero_division=0)
    acc = accuracy_score(targets_np, preds)
    print(f"{th:.2f}       | {f1:.4f}     | {acc:.4f}")
    if f1 > best_f1:
        best_f1 = f1
        best_th = th

# ìµœì¢… ì§€í‘œ ê³„ì‚°
final_preds = (probs_np > best_th).astype(int)
final_acc = accuracy_score(targets_np, final_preds)
final_f1 = f1_score(targets_np, final_preds)
final_recall = recall_score(targets_np, final_preds)

# ----------------------------------------------------
# 5. [ìµœì¢… ë¹„êµ] GRU vs DA-RNN (Max Pool)
# ----------------------------------------------------
# GRU ì ìˆ˜ (íšŒì›ë‹˜ì´ ì£¼ì‹  ê¸°ë¡ ê¸°ì¤€)
gru_acc = 0.9513
gru_f1 = 0.9196
gru_recall = 0.8721

print("\n" + "#"*60)
print("ğŸ“¢ [FINAL BATTLE] GRU(Original) vs DA-RNN(Max Pool)")
print("#"*60)
print(f"{'Metric':<15} | {'GRU (Baseline)':<15} | {'DA-RNN (Ours)':<15} | {'Gap'}")
print("-" * 65)
print(f"{'Accuracy':<15} | {gru_acc:.4f}          | {final_acc:.4f}          | {final_acc - gru_acc:+.4f}")
print(f"{'F1 Score':<15} | {gru_f1:.4f}          | {final_f1:.4f}          | {final_f1 - gru_f1:+.4f}")
print(f"{'Recall':<15} | {gru_recall:.4f}          | {final_recall:.4f}          | {final_recall - gru_recall:+.4f}")
print("-" * 65)
print(f"â€» DA-RNN Threshold: {best_th:.2f}")

# í˜¼ë™ í–‰ë ¬ ì €ì¥
cm = confusion_matrix(targets_np, final_preds)
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')
plt.title(f'DA-RNN (Max Pool) Confusion Matrix\nF1: {final_f1:.4f}')
plt.savefig('confusion_matrix_maxpool.png')
print("ğŸ–¼ï¸ ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥: confusion_matrix_maxpool.png")