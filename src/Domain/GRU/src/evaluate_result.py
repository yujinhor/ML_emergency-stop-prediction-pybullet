import torch
import torch.nn as nn
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import accuracy_score, f1_score, recall_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import matplotlib.pyplot as plt
import sys
import os

# ----------------------------------------------------
# 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì „ì²˜ë¦¬ (í•™ìŠµê³¼ ë™ì¼í•˜ê²Œ!)
# ----------------------------------------------------
# Mac í•œê¸€ ì„¤ì •
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False
device = torch.device("cpu") # í‰ê°€ëŠ” CPUë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤
INPUT_SIZE = 8 # Brake_Torque ì œê±°ë¨

def load_and_preprocess_data():
    print("ğŸ“‚ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬(Brake ì œê±°, í‘œì¤€í™”) ì¤‘...")
    
    # 1. íŒŒì¼ ë¡œë“œ (Train ë°ì´í„°ëŠ” ìŠ¤ì¼€ì¼ ê¸°ì¤€ì„ ì¡ê¸° ìœ„í•´ í•„ìš”)
    X_train_np = np.load('X_train.npy')
    X_test_np = np.load('X_test.npy')
    y_test = np.load('y_test.npy')
    
    # 2. Brake_Torque (7ë²ˆì§¸ ì¸ë±ìŠ¤) ì œê±°
    X_train_np = np.delete(X_train_np, 7, axis=2)
    X_test_np = np.delete(X_test_np, 7, axis=2)
    
    # 3. StandardScaler ì ìš©
    scaler = StandardScaler()
    N, T, F = X_train_np.shape
    
    # Train ë°ì´í„°ë¡œ í”¼íŒ… (í‰ê· /ë¶„ì‚° í•™ìŠµ)
    X_train_2d = X_train_np.reshape(N * T, F)
    scaler.fit(X_train_2d) 
    
    # Test ë°ì´í„° ë³€í™˜
    N_test, T_test, _ = X_test_np.shape
    X_test_2d = X_test_np.reshape(N_test * T_test, F)
    X_test_scaled = scaler.transform(X_test_2d)
    X_test_final = X_test_scaled.reshape(N_test, T_test, F)
    
    # Tensor ë³€í™˜
    X_test_tensor = torch.tensor(X_test_final, dtype=torch.float32).to(device)
    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)
    
    return X_test_tensor, y_test_tensor

X_test, y_test = load_and_preprocess_data()
test_dataset = TensorDataset(X_test, y_test)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
print("âœ… ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ!")


# ----------------------------------------------------
# 2. ëª¨ë¸ êµ¬ì¡° ì •ì˜ ë° ë¡œë“œ
# ----------------------------------------------------
class RobotGRU(nn.Module):
    def __init__(self, input_size=8, hidden_size=64, num_layers=2, output_size=1):
        super(RobotGRU, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.gru(x, h0)
        logits = self.fc(out[:, -1, :])
        return torch.sigmoid(logits)

model = RobotGRU(input_size=INPUT_SIZE).to(device)
try:
    # í•™ìŠµëœ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
    model.load_state_dict(torch.load('gru_model_best.pth', map_location=device))
    model.eval()
    print("âœ… í•™ìŠµëœ Best Model ë¡œë“œ ì„±ê³µ!")
except FileNotFoundError:
    print("âŒ ì˜¤ë¥˜: 'gru_model_best.pth' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit()


# ----------------------------------------------------
# 3. ì˜ˆì¸¡ ì‹¤í–‰ (ë‹¨ 1íšŒë§Œ ìˆ˜í–‰í•˜ì—¬ ì†ë„ ìµœì í™”)
# ----------------------------------------------------
def get_all_probabilities(model, loader):
    print("ğŸ¤– ëª¨ë¸ ì˜ˆì¸¡(Inference) ì‹¤í–‰ ì¤‘...")
    all_probs = []
    with torch.no_grad():
        for inputs, _ in loader:
            outputs = model(inputs)
            all_probs.extend(outputs.numpy().flatten())
    return np.array(all_probs)

# ì˜ˆì¸¡ê°’ ë¯¸ë¦¬ ê³„ì‚°
targets_np = y_test.numpy().flatten()
all_probs_np = get_all_probabilities(model, test_loader)
print("âœ… ì˜ˆì¸¡ ì™„ë£Œ! í‰ê°€ ì§€í‘œ ê³„ì‚° ì‹œì‘...")


# ----------------------------------------------------
# 4. ìµœì  ì„ê³„ì¹˜(Threshold) íƒìƒ‰
# ----------------------------------------------------
print("\n" + "="*50)
print("ğŸ” [ì‹¬í™” ë¶„ì„] ìµœì ì˜ ì„ê³„ì¹˜(Threshold) íƒìƒ‰")
print("="*50)
print(f"{'Threshold':<10} | {'Accuracy':<10} | {'F1 Score':<10} | {'Recall':<10}")
print("-" * 50)

best_f1 = 0
best_th = 0.5

# 0.1ë¶€í„° 0.9ê¹Œì§€ 0.05 ë‹¨ìœ„ë¡œ í…ŒìŠ¤íŠ¸
for th in np.arange(0.1, 0.91, 0.05):
    preds = (all_probs_np > th).astype(int)
    acc = accuracy_score(targets_np, preds)
    f1 = f1_score(targets_np, preds, zero_division=0)
    recall = recall_score(targets_np, preds, zero_division=0)
    
    print(f"{th:.2f}       | {acc:.4f}     | {f1:.4f}     | {recall:.4f}")
    
    if f1 > best_f1:
        best_f1 = f1
        best_th = th

print("-" * 50)
print(f"ğŸ’¡ ì¶”ì²œ: F1 ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ì„ê³„ì¹˜ëŠ” {best_th:.2f} ì…ë‹ˆë‹¤. (Max F1: {best_f1:.4f})")


# ----------------------------------------------------
# 5. ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸ (ìµœì  ì„ê³„ì¹˜ ê¸°ì¤€)
# ----------------------------------------------------
final_preds = (all_probs_np > best_th).astype(int)

print("\n" + "="*50)
print(f"ğŸ“¢ [ìµœì¢… ì„±ì í‘œ] Threshold = {best_th:.2f}")
print("="*50)
print(f"ì •í™•ë„ (Accuracy) : {accuracy_score(targets_np, final_preds):.4f}")
print(f"F1 Score        : {f1_score(targets_np, final_preds):.4f}")
print(f"ì¬í˜„ìœ¨ (Recall)  : {recall_score(targets_np, final_preds):.4f}")
print(f"ì •ë°€ë„ (Precision): {best_f1 / recall_score(targets_np, final_preds) * 0.5 if recall_score(targets_np, final_preds) else 0:.4f} (ì¶”ì •)")
print("-" * 50)
print("ë¶„ë¥˜ ë³´ê³ ì„œ:\n", classification_report(targets_np, final_preds))

# í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
cm = confusion_matrix(targets_np, final_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['ì •ìƒ(0)', 'ê³ ì¥(1)'], yticklabels=['ì •ìƒ(0)', 'ê³ ì¥(1)'])
plt.xlabel(f'ì˜ˆì¸¡ê°’ (Predicted) @ Th={best_th:.2f}')
plt.ylabel('ì‹¤ì œê°’ (Actual)')
plt.title('Confusion Matrix (ìµœì¢…)')
plt.savefig('confusion_matrix_final.png')
print("ğŸ–¼ï¸ 'confusion_matrix_final.png' ì €ì¥ ì™„ë£Œ!")